#!/usr/bin/env python3
"""
æµ‹è¯•åŒæ¨¡å¼APIåŠŸèƒ½çš„ç®€å•è„šæœ¬
"""

import os
import sys
import asyncio
from core.api_config import APIConfig, APIMode, ModelConfig
from core.api_factory import APIClientFactory
from core.research_engine import ResearchEngine

async def test_dual_mode():
    """æµ‹è¯•åŒæ¨¡å¼åŠŸèƒ½"""
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("âŒ è¯·è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    print("ğŸ” DeepSearch åŒæ¨¡å¼APIæµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•1: Google GenAIæ¨¡å¼
    print("\nğŸ“‹ æµ‹è¯•1: Google GenAIæ¨¡å¼")
    try:
        engine_genai = ResearchEngine(
            api_key=api_key,
            model_name="gemini-2.0-flash",
            preferred_mode=APIMode.GENAI
        )
        
        client_info = engine_genai.get_client_info()
        print(f"âœ… GenAIæ¨¡å¼åˆå§‹åŒ–æˆåŠŸ")
        print(f"   æœç´¢å®¢æˆ·ç«¯: {client_info['search_client']['type']}")
        print(f"   å·¥ä½œæµå®¢æˆ·ç«¯: {client_info['workflow_client']['type']}")
        
        await engine_genai.close_clients()
        
    except Exception as e:
        print(f"âŒ GenAIæ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•2: OpenAIå…¼å®¹æ¨¡å¼ï¼ˆå¦‚æœæœ‰OpenAI APIå¯†é’¥ï¼‰
    openai_key = os.getenv("OPENAI_API_KEY")
    if openai_key:
        print("\nğŸ“‹ æµ‹è¯•2: OpenAIå…¼å®¹æ¨¡å¼")
        try:
            # é…ç½®OpenAIæ¨¡å¼
            APIConfig.update_global_setting("openai_api_key", openai_key)
            
            engine_openai = ResearchEngine(
                api_key=openai_key,
                model_name="gpt-3.5-turbo",
                preferred_mode=APIMode.OPENAI
            )
            
            client_info = engine_openai.get_client_info()
            print(f"âœ… OpenAIæ¨¡å¼åˆå§‹åŒ–æˆåŠŸ")
            print(f"   æœç´¢å®¢æˆ·ç«¯: {client_info['search_client']['type']}")
            print(f"   å·¥ä½œæµå®¢æˆ·ç«¯: {client_info['workflow_client']['type']}")
            
            await engine_openai.close_clients()
            
        except Exception as e:
            print(f"âŒ OpenAIæ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
    else:
        print("\nâš ï¸  è·³è¿‡OpenAIæ¨¡å¼æµ‹è¯•ï¼ˆæœªè®¾ç½®OPENAI_API_KEYï¼‰")
    
    # æµ‹è¯•3: é…ç½®ç®¡ç†
    print("\nğŸ“‹ æµ‹è¯•3: é…ç½®ç®¡ç†")
    try:
        # æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹é…ç½®
        custom_model = ModelConfig(
            name="test-model",
            mode=APIMode.OPENAI,
            supports_search=False,
            supports_tools=True,
            base_url="https://api.example.com/v1",
            default_params={"temperature": 0.5, "max_tokens": 2048}
        )
        
        APIConfig.add_model_config("test-model", custom_model)
        
        available_models = APIConfig.get_available_models()
        if "test-model" in available_models:
            print("âœ… è‡ªå®šä¹‰æ¨¡å‹é…ç½®æˆåŠŸ")
        else:
            print("âŒ è‡ªå®šä¹‰æ¨¡å‹é…ç½®å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ é…ç½®ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•4: å®¢æˆ·ç«¯å·¥å‚
    print("\nğŸ“‹ æµ‹è¯•4: å®¢æˆ·ç«¯å·¥å‚")
    try:
        factory = APIClientFactory()
        
        # æµ‹è¯•GenAIå®¢æˆ·ç«¯åˆ›å»º
        genai_client = factory.create_client(
            model_name="gemini-2.0-flash",
            api_key=api_key,
            preferred_mode=APIMode.GENAI
        )
        
        print(f"âœ… GenAIå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: {type(genai_client).__name__}")
        
        # æµ‹è¯•å®¢æˆ·ç«¯èƒ½åŠ›
        print(f"   æ”¯æŒæœç´¢: {genai_client.supports_search()}")
        print(f"   æ”¯æŒå·¥å…·: {genai_client.supports_tools()}")
        
    except Exception as e:
        print(f"âŒ å®¢æˆ·ç«¯å·¥å‚æµ‹è¯•å¤±è´¥: {e}")
    
    print("\nğŸ‰ åŒæ¨¡å¼APIæµ‹è¯•å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    try:
        asyncio.run(test_dual_mode())
    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

if __name__ == "__main__":
    main() 