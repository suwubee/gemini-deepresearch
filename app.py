"""
DeepSearch - æ™ºèƒ½æ·±åº¦ç ”ç©¶åŠ©æ‰‹
åŸºäº Streamlit çš„ä¸»åº”ç”¨ç¨‹åºï¼Œæ”¯æŒå®æ—¶è¿›åº¦æ˜¾ç¤º
"""

import streamlit as st
import asyncio
import json
import os
import time
import threading
import concurrent.futures
from datetime import datetime
from typing import Dict, Any
from enum import Enum
import queue

# from streamlit_local_storage import LocalStorage  # æš‚æ—¶ç¦ç”¨ï¼Œæœ‰bug
import streamlit.components.v1 as components

class SafeLocalStorage:
    """å®‰å…¨çš„LocalStorageå®ç°ï¼Œä½¿ç”¨session stateä½œä¸ºä¸»è¦å­˜å‚¨"""
    
    def __init__(self):
        self._cache = {}
        self._cache_file = ".streamlit_cache.json"
    
    def _load_from_file_cache(self):
        """ä»æ–‡ä»¶ç¼“å­˜åŠ è½½æ•°æ®"""
        try:
            if os.path.exists(self._cache_file):
                with open(self._cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception:
            pass
        return {}
    
    def _save_to_file_cache(self, data):
        """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶ç¼“å­˜"""
        try:
            with open(self._cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception:
            pass
    
    def getItem(self, key, default=None):
        """ä»session stateæˆ–æ–‡ä»¶ç¼“å­˜è·å–æ•°æ®"""
        # é¦–å…ˆæ£€æŸ¥session stateç¼“å­˜
        session_key = f"ls_{key}"
        if session_key in st.session_state:
            cached_value = st.session_state[session_key]
            if cached_value is not None and cached_value != "null" and str(cached_value).strip() != "":
                return cached_value
        
        # å¦‚æœsession stateä¸­æ²¡æœ‰ï¼Œå°è¯•ä»æ–‡ä»¶ç¼“å­˜åŠ è½½
        if not hasattr(st.session_state, '_file_cache_loaded'):
            file_cache = self._load_from_file_cache()
            if file_cache:
                for cache_key, cache_value in file_cache.items():
                    if cache_value is not None and str(cache_value).strip() != "":
                        st.session_state[f"ls_{cache_key}"] = cache_value
                st.session_state._file_cache_loaded = True
                
                # å†æ¬¡æ£€æŸ¥session state
                if session_key in st.session_state:
                    cached_value = st.session_state[session_key]
                    if cached_value is not None and cached_value != "null" and str(cached_value).strip() != "":
                        return cached_value
        
        # å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›é»˜è®¤å€¼
        return default
    
    def setItem(self, key, value):
        """å‘LocalStorageã€session stateå’Œæ–‡ä»¶ç¼“å­˜ä¿å­˜æ•°æ®"""
        try:
            # ç¼“å­˜åˆ°session state
            session_key = f"ls_{key}"
            st.session_state[session_key] = value
            self._cache[key] = value
            
            # ä¿å­˜åˆ°æ–‡ä»¶ç¼“å­˜
            try:
                file_cache = self._load_from_file_cache()
                file_cache[key] = value
                self._save_to_file_cache(file_cache)
            except Exception:
                pass  # æ–‡ä»¶ç¼“å­˜å¤±è´¥ä¸å½±å“ä¸»è¦åŠŸèƒ½
            
            # ä½¿ç”¨HTML/JSæ–¹æ³•ä¿å­˜åˆ°æµè§ˆå™¨LocalStorage
            if isinstance(value, str):
                # å¯¹äºJSONå­—ç¬¦ä¸²ï¼Œéœ€è¦æ›´ä»”ç»†çš„è½¬ä¹‰
                escaped_value = (value.replace('\\', '\\\\')
                               .replace("'", "\\'")
                               .replace('"', '\\"')
                               .replace('\n', '\\n')
                               .replace('\r', '\\r')
                               .replace('\t', '\\t'))
            else:
                escaped_value = str(value).replace("'", "\\'").replace('"', '\\"')
            
            html_code = f"""
            <script>
                try {{
                    localStorage.setItem('{key}', '{escaped_value}');
                    console.log('Saved to localStorage:', '{key}');
                }} catch (e) {{
                    console.error('LocalStorage save error:', e);
                }}
            </script>
            """
            components.html(html_code, height=0)
            
            return True
        except Exception as e:
            st.warning(f"ä¿å­˜åˆ°LocalStorageå¤±è´¥: {e}")
            return False
    
    def removeItem(self, key):
        """ä»LocalStorageã€session stateå’Œæ–‡ä»¶ç¼“å­˜åˆ é™¤æ•°æ®"""
        try:
            # ä»ç¼“å­˜ä¸­åˆ é™¤
            if key in self._cache:
                del self._cache[key]
            
            # ä»session stateä¸­åˆ é™¤
            session_key = f"ls_{key}"
            if session_key in st.session_state:
                del st.session_state[session_key]
            
            # ä»æ–‡ä»¶ç¼“å­˜ä¸­åˆ é™¤
            try:
                file_cache = self._load_from_file_cache()
                if key in file_cache:
                    del file_cache[key]
                    self._save_to_file_cache(file_cache)
            except Exception:
                pass  # æ–‡ä»¶ç¼“å­˜å¤±è´¥ä¸å½±å“ä¸»è¦åŠŸèƒ½
            
            # ä½¿ç”¨HTML/JSæ–¹æ³•ä»æµè§ˆå™¨LocalStorageä¸­åˆ é™¤
            html_code = f"""
            <script>
                try {{
                    localStorage.removeItem('{key}');
                    console.log('Removed from localStorage:', '{key}');
                }} catch (e) {{
                    console.error('LocalStorage remove error:', e);
                }}
            </script>
            """
            components.html(html_code, height=0)
            
            return True
        except Exception as e:
            st.warning(f"ä»LocalStorageåˆ é™¤å¤±è´¥: {e}")
            return False

# å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from core.research_engine import ResearchEngine
from core.state_manager import TaskStatus
from core.api_config import APIConfig, APIMode, ModelConfig
from core.api_factory import APIClientFactory
from utils.debug_logger import enable_debug, disable_debug, get_debug_logger
from utils.streamlit_helpers import (
    json_serializable,
    create_markdown_content,
    display_task_analysis,
    display_search_results,
    display_final_answer,
)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ğŸ” DeepSearch",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼ˆåŸºäºæµ‹è¯•ç»“æœæ›´æ–°ï¼‰
AVAILABLE_MODELS = {
    "gemini-2.0-flash": "ğŸš€ Gemini 2.0 Flash - ä¾¿å®œæœ€å¿«",
    "gemini-2.5-flash-preview-05-20": "âš¡ Gemini 2.5 Flash - æœ€æ–°åŠŸèƒ½", 
    "gemini-2.5-pro-preview-06-05": "ğŸ’« Gemini 2.5 Pro - 0605æœ€æ–°"
}

# ä»»åŠ¡ç±»å‹åˆ°æ¨¡å‹çš„æ˜ å°„
TASK_MODEL_MAPPING = {
    "search": "æœç´¢æ¨¡å‹",
    "task_analysis": "ä»»åŠ¡åˆ†ææ¨¡å‹", 
    "reflection": "åæ€åˆ†ææ¨¡å‹",
    "answer": "ç­”æ¡ˆç”Ÿæˆæ¨¡å‹"
}

# æœç´¢æ¨¡å¼é€‰é¡¹
SEARCH_MODE_OPTIONS = {
    "genai": "ğŸ”µ GenAI (æ¨èï¼Œæ”¯æŒæœç´¢)",
    "openai": "ğŸŸ  OpenAIå…¼å®¹ (æ— æœç´¢åŠŸèƒ½)",
    "auto": "ğŸ”„ è‡ªåŠ¨é€‰æ‹©"
}

# APIæ¨¡å¼é€‰é¡¹
API_MODE_OPTIONS = {
    APIMode.GENAI: "ğŸ”µ Google GenAI SDK (æ¨è)",
    APIMode.OPENAI: "ğŸŸ  OpenAIå…¼å®¹ HTTP API",
    APIMode.AUTO: "ğŸ”„ è‡ªåŠ¨é€‰æ‹©"
}

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    .thinking-box {
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 10px;
        background-color: #f0f8ff;
        border-left: 4px solid #4169e1;
        animation: pulse 2s infinite;
    }
    
    @keyframes pulse {
        0% { opacity: 0.8; }
        50% { opacity: 1; }
        100% { opacity: 0.8; }
    }
    
    .progress-step {
        padding: 0.5rem;
        margin: 0.2rem 0;
        border-radius: 5px;
        background-color: #f8f9fa;
        border-left: 3px solid #28a745;
    }
</style>
""", unsafe_allow_html=True)


def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    defaults = {
        "research_engine": None,
        "current_task": None,
        "research_results": [],
        "progress_messages": [],
        "api_key_validated": False,
        "is_researching": False,
        "current_step": "",
        "progress_percentage": 0,
        "model_name": "gemini-2.0-flash",
        "research_complete": False,
        "research_error": None,
        "research_started": False,  # æ·»åŠ æ‰§è¡Œæ ‡è®°
        "just_completed": False,    # åˆšåˆšå®Œæˆæ ‡è®°
        "debug_enabled": False,     # debugæ¨¡å¼å¼€å…³
        "show_markdown_preview": False,  # markdowné¢„è§ˆå¼€å…³
        
        # åŒæ¨¡å¼APIé…ç½®
        "api_mode": APIMode.GENAI,
        "openai_config": {
            'base_url': 'https://api.openai.com/v1',
            'api_key': '',
            'timeout': 30
        },
        "task_models": {
            'search': 'gemini-2.0-flash',
            'task_analysis': 'gemini-2.5-flash-preview-05-20',
            'reflection': 'gemini-2.5-flash-preview-05-20', 
            'answer': 'gemini-2.5-pro-preview-06-05'
        },
        "search_mode": "genai",  # æœç´¢æ¨¡å‹ç‹¬ç«‹çš„æ¨¡å¼é…ç½®
        "custom_models": [],
        "config_changed": False
    }
    
    for key, default_value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

    # åˆå§‹åŒ–LocalStorageæ•°æ®åŠ è½½
    initialize_from_localstorage()

    # å°è¯•ä»LocalStorageåŠ è½½APIå¯†é’¥
    try:
        if "ls_api_key" not in st.session_state:
            localS = SafeLocalStorage()
            initial_api_key = localS.getItem("api_key")
            st.session_state.ls_api_key = initial_api_key
        else:
            initial_api_key = st.session_state.ls_api_key
            
        if (initial_api_key and 
            initial_api_key != "null" and 
            initial_api_key != None and
            str(initial_api_key).strip() != ""):
            st.session_state.api_key_to_load = initial_api_key
    except Exception:
        pass  # å¿½ç•¥LocalStorageåŠ è½½é”™è¯¯


def initialize_from_localstorage():
    """åœ¨åº”ç”¨å¯åŠ¨æ—¶ä»æµè§ˆå™¨LocalStorageåŠ è½½æ•°æ®åˆ°session state"""
    if 'localstorage_initialized' not in st.session_state:
        # åˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„ä¼šè¯IDæ¥æ ‡è¯†è¿™æ¬¡åŠ è½½
        session_id = str(hash(str(st.session_state)))[-8:]
        
        # åˆ›å»ºJavaScriptä»£ç æ¥è¯»å–LocalStorageå¹¶é€šè¿‡URLå‚æ•°ä¼ é€’æ•°æ®
        html_code = f"""
        <script>
            function loadFromLocalStorage() {{
                try {{
                    // è¯»å–APIå¯†é’¥
                    const apiKey = localStorage.getItem('api_key');
                    if (apiKey && apiKey !== 'null' && apiKey.trim() !== '') {{
                        console.log('Found API key in localStorage, length:', apiKey.length);
                        // å°†APIå¯†é’¥å­˜å‚¨åˆ°ä¸€ä¸ªéšè—çš„metaæ ‡ç­¾ä¸­
                        let metaApiKey = document.querySelector('meta[name="ls-api-key"]');
                        if (!metaApiKey) {{
                            metaApiKey = document.createElement('meta');
                            metaApiKey.name = 'ls-api-key';
                            document.head.appendChild(metaApiKey);
                        }}
                        metaApiKey.content = apiKey;
                    }}
                    
                    // è¯»å–ç ”ç©¶ç»“æœ
                    const researchResults = localStorage.getItem('research_results');
                    if (researchResults && researchResults !== 'null' && researchResults.trim() !== '') {{
                        console.log('Found research results in localStorage, length:', researchResults.length);
                        // å°†ç ”ç©¶ç»“æœå­˜å‚¨åˆ°ä¸€ä¸ªéšè—çš„metaæ ‡ç­¾ä¸­
                        let metaResults = document.querySelector('meta[name="ls-research-results"]');
                        if (!metaResults) {{
                            metaResults = document.createElement('meta');
                            metaResults.name = 'ls-research-results';
                            document.head.appendChild(metaResults);
                        }}
                        metaResults.content = researchResults;
                    }}
                    
                    console.log('LocalStorage data loaded to meta tags');
                }} catch (e) {{
                    console.error('Error loading LocalStorage:', e);
                }}
            }}
            
            // é¡µé¢åŠ è½½å®Œæˆåæ‰§è¡ŒåŠ è½½
            if (document.readyState === 'loading') {{
                document.addEventListener('DOMContentLoaded', loadFromLocalStorage);
            }} else {{
                loadFromLocalStorage();
            }}
        </script>
        """
        
        components.html(html_code, height=0)
        st.session_state['localstorage_initialized'] = True


def load_config_from_storage():
    """ä»LocalStorageåŠ è½½é…ç½®"""
    localS = SafeLocalStorage()
    
    try:
        # åŠ è½½APIæ¨¡å¼
        api_mode_str = localS.getItem("api_mode")
        if api_mode_str:
            try:
                st.session_state.api_mode = APIMode(api_mode_str)
            except:
                st.session_state.api_mode = APIMode.GENAI
        
        # åŠ è½½OpenAIé…ç½®
        openai_config = localS.getItem("openai_config")
        if openai_config:
            try:
                import json
                st.session_state.openai_config = json.loads(openai_config)
            except:
                pass
        
        # åŠ è½½ä»»åŠ¡æ¨¡å‹é…ç½®
        task_models = localS.getItem("task_models")
        if task_models:
            try:
                import json
                st.session_state.task_models = json.loads(task_models)
            except:
                pass
        
        # åŠ è½½è‡ªå®šä¹‰æ¨¡å‹
        custom_models = localS.getItem("custom_models")
        if custom_models:
            try:
                import json
                st.session_state.custom_models = json.loads(custom_models)
            except:
                pass
                
    except Exception as e:
        st.warning(f"åŠ è½½é…ç½®å¤±è´¥: {e}")


def save_config_to_storage():
    """ä¿å­˜é…ç½®åˆ°LocalStorage"""
    localS = SafeLocalStorage()
    
    try:
        # ä¿å­˜APIæ¨¡å¼
        localS.setItem("api_mode", st.session_state.api_mode.value)
        
        # ä¿å­˜OpenAIé…ç½®
        import json
        localS.setItem("openai_config", json.dumps(st.session_state.openai_config))
        
        # ä¿å­˜ä»»åŠ¡æ¨¡å‹é…ç½®
        localS.setItem("task_models", json.dumps(st.session_state.task_models))
        
        # ä¿å­˜è‡ªå®šä¹‰æ¨¡å‹
        localS.setItem("custom_models", json.dumps(st.session_state.custom_models))
        
    except Exception as e:
        st.warning(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")


def update_api_config():
    """æ›´æ–°APIé…ç½®åˆ°APIConfig"""
    try:
        # æ›´æ–°å…¨å±€è®¾ç½®
        APIConfig.update_global_setting("gemini_2_0_preferred_mode", st.session_state.api_mode)
        
        # æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹åˆ°APIConfig
        for custom_model in st.session_state.custom_models:
            model_config = ModelConfig(
                name=custom_model["name"],
                mode=APIMode.OPENAI,
                supports_search=custom_model.get("supports_search", False),
                supports_tools=custom_model.get("supports_tools", True),
                base_url=custom_model.get("base_url", st.session_state.openai_config["base_url"]),
                default_params=custom_model.get("default_params", {"temperature": 0.3, "max_tokens": 4096})
            )
            APIConfig.add_model_config(custom_model["name"], model_config)
        
        # æ›´æ–°OpenAIå…¼å®¹é…ç½®
        if st.session_state.openai_config["base_url"] != "https://api.openai.com/v1":
            custom_openai_config = {
                "base_url": st.session_state.openai_config["base_url"],
                "headers": {"Content-Type": "application/json"},
                "timeout": st.session_state.openai_config["timeout"],
                "retry_count": 3
            }
            APIConfig.OPENAI_COMPATIBLE_CONFIGS["custom"] = custom_openai_config
            
    except Exception as e:
        st.error(f"æ›´æ–°APIé…ç½®å¤±è´¥: {e}")


def validate_and_setup_engine(api_key: str, model_name: str) -> bool:
    """éªŒè¯APIå¯†é’¥å¹¶è®¾ç½®å¼•æ“"""
    if not api_key or len(api_key) < 10:
        return False
    
    try:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆ›å»ºå¼•æ“
        need_recreate = (
            st.session_state.research_engine is None or 
            st.session_state.model_name != model_name or
            st.session_state.config_changed
        )
        
        if need_recreate:
            # æ›´æ–°APIé…ç½®
            update_api_config()
            
            # æ ¹æ®APIæ¨¡å¼åˆ›å»ºå¼•æ“
            if st.session_state.api_mode == APIMode.OPENAI:
                # ä½¿ç”¨OpenAIæ¨¡å¼æ—¶ï¼Œéœ€è¦è®¾ç½®APIå¯†é’¥
                if not st.session_state.openai_config.get("api_key"):
                    st.session_state.openai_config["api_key"] = api_key
            
            # ä½¿ç”¨ä»»åŠ¡æ¨¡å‹é…ç½®åˆ›å»ºå¼•æ“
            engine = ResearchEngine(
                api_key=api_key,
                model_name=st.session_state.task_models.get("search", model_name),
                preferred_mode=st.session_state.api_mode
            )
            
            # æ›´æ–°å¼•æ“çš„æ¨¡å‹é…ç½®
            if hasattr(engine, 'client_manager') and hasattr(engine.client_manager, 'update_config'):
                try:
                    engine.client_manager.update_config(
                        search_model=st.session_state.task_models.get("search", model_name),
                        analysis_model=st.session_state.task_models.get("task_analysis", model_name),
                        answer_model=st.session_state.task_models.get("answer", model_name)
                    )
                except Exception as e:
                    st.warning(f"æ›´æ–°æ¨¡å‹é…ç½®æ—¶å‡ºç°è­¦å‘Š: {e}")
            
            st.session_state.research_engine = engine
            st.session_state.model_name = model_name
            st.session_state.config_changed = False
            
        return True
    except Exception as e:
        st.error(f"APIå¯†é’¥éªŒè¯å¤±è´¥: {str(e)}")
        return False


def export_config():
    """å¯¼å‡ºé…ç½®åˆ°JSONæ–‡ä»¶"""
    try:
        config_data = {
            "api_mode": st.session_state.api_mode.value,
            "openai_config": st.session_state.openai_config,
            "task_models": st.session_state.task_models,
            "custom_models": st.session_state.custom_models,
            "export_time": datetime.now().isoformat(),
            "version": "1.0"
        }
        
        # ç§»é™¤æ•æ„Ÿä¿¡æ¯
        safe_config = config_data.copy()
        if "api_key" in safe_config["openai_config"]:
            safe_config["openai_config"]["api_key"] = "***HIDDEN***"
        
        config_json = json.dumps(safe_config, indent=2, ensure_ascii=False)
        
        st.sidebar.download_button(
            label="ğŸ’¾ ä¸‹è½½é…ç½®æ–‡ä»¶",
            data=config_json,
            file_name=f"deepsearch_config_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            help="ä¸‹è½½é…ç½®æ–‡ä»¶ï¼ˆä¸åŒ…å«APIå¯†é’¥ï¼‰"
        )
        
        st.sidebar.success("âœ… é…ç½®å·²å‡†å¤‡ä¸‹è½½")
        
    except Exception as e:
        st.sidebar.error(f"âŒ å¯¼å‡ºé…ç½®å¤±è´¥: {e}")


def import_config(uploaded_file):
    """å¯¼å…¥é…ç½®æ–‡ä»¶"""
    try:
        config_data = json.load(uploaded_file)
        
        # éªŒè¯é…ç½®æ–‡ä»¶æ ¼å¼
        required_keys = ["api_mode", "openai_config", "task_models"]
        if not all(key in config_data for key in required_keys):
            st.sidebar.error("âŒ é…ç½®æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
            return
        
        # å¯¼å…¥é…ç½®
        try:
            st.session_state.api_mode = APIMode(config_data["api_mode"])
        except:
            st.session_state.api_mode = APIMode.GENAI
        
        # ä¿ç•™å½“å‰çš„APIå¯†é’¥
        current_api_key = st.session_state.openai_config.get("api_key", "")
        st.session_state.openai_config = config_data["openai_config"]
        if current_api_key and not st.session_state.openai_config.get("api_key"):
            st.session_state.openai_config["api_key"] = current_api_key
        
        st.session_state.task_models = config_data["task_models"]
        
        if "custom_models" in config_data:
            st.session_state.custom_models = config_data["custom_models"]
        
        st.session_state.config_changed = True
        save_config_to_storage()
        
        st.sidebar.success("âœ… é…ç½®å¯¼å…¥æˆåŠŸ")
        st.rerun()
        
    except Exception as e:
        st.sidebar.error(f"âŒ å¯¼å…¥é…ç½®å¤±è´¥: {e}")


def reset_config():
    """é‡ç½®é…ç½®åˆ°é»˜è®¤å€¼"""
    try:
        # ä¿ç•™å½“å‰çš„APIå¯†é’¥
        current_gemini_key = st.session_state.get("api_key_to_load", "")
        current_openai_key = st.session_state.openai_config.get("api_key", "")
        
        # é‡ç½®åˆ°é»˜è®¤å€¼
        st.session_state.api_mode = APIMode.GENAI
        st.session_state.openai_config = {
            'base_url': 'https://api.openai.com/v1',
            'api_key': current_openai_key,
            'timeout': 30
        }
        st.session_state.task_models = {
            'search': 'gemini-2.0-flash',
            'task_analysis': 'gemini-2.5-flash-preview-05-20',
            'reflection': 'gemini-2.5-flash-preview-05-20', 
            'answer': 'gemini-2.5-pro-preview-06-05'
        }
        st.session_state.custom_models = []
        st.session_state.config_changed = True
        
        # æ¢å¤APIå¯†é’¥
        if current_gemini_key:
            st.session_state.api_key_to_load = current_gemini_key
        
        save_config_to_storage()
        
        st.sidebar.success("âœ… é…ç½®å·²é‡ç½®")
        st.rerun()
        
    except Exception as e:
        st.sidebar.error(f"âŒ é‡ç½®é…ç½®å¤±è´¥: {e}")


def setup_api_configuration():
    """è®¾ç½®APIé…ç½®ç•Œé¢"""
    st.sidebar.header("ğŸ”§ APIé…ç½®")
    
    # åŠ è½½é…ç½®
    load_config_from_storage()
    
    localS = SafeLocalStorage()
    
    # APIæ¨¡å¼é€‰æ‹©
    api_mode = st.sidebar.selectbox(
        "APIæ¨¡å¼",
        options=list(API_MODE_OPTIONS.keys()),
        index=list(API_MODE_OPTIONS.keys()).index(st.session_state.api_mode),
        format_func=lambda x: API_MODE_OPTIONS[x],
        help="é€‰æ‹©APIè°ƒç”¨æ¨¡å¼"
    )
    
    if api_mode != st.session_state.api_mode:
        st.session_state.api_mode = api_mode
        st.session_state.config_changed = True
        save_config_to_storage()
    
    # æ ¹æ®æ¨¡å¼æ˜¾ç¤ºä¸åŒçš„é…ç½®
    if st.session_state.api_mode == APIMode.OPENAI:
        st.sidebar.subheader("ğŸŸ  OpenAIå…¼å®¹é…ç½®")
        
        # Base URLé…ç½®
        base_url = st.sidebar.text_input(
            "Base URL",
            value=st.session_state.openai_config["base_url"],
            help="OpenAIå…¼å®¹APIçš„åŸºç¡€URL"
        )
        
        # APIå¯†é’¥é…ç½®
        openai_api_key = st.sidebar.text_input(
            "API Key",
            type="password",
            value=st.session_state.openai_config.get("api_key", ""),
            help="OpenAIå…¼å®¹APIçš„å¯†é’¥"
        )
        
        # è¶…æ—¶é…ç½®
        timeout = st.sidebar.number_input(
            "è¯·æ±‚è¶…æ—¶(ç§’)",
            min_value=10,
            max_value=120,
            value=st.session_state.openai_config["timeout"],
            help="APIè¯·æ±‚è¶…æ—¶æ—¶é—´"
        )
        
        # æ›´æ–°OpenAIé…ç½®
        if (base_url != st.session_state.openai_config["base_url"] or
            openai_api_key != st.session_state.openai_config.get("api_key", "") or
            timeout != st.session_state.openai_config["timeout"]):
            
            st.session_state.openai_config.update({
                "base_url": base_url,
                "api_key": openai_api_key,
                "timeout": timeout
            })
            st.session_state.config_changed = True
            save_config_to_storage()
        
        # æ˜¾ç¤ºå½“å‰é…ç½®çŠ¶æ€
        if base_url and openai_api_key:
            st.sidebar.success("âœ… OpenAIé…ç½®å®Œæˆ")
        else:
            st.sidebar.warning("âš ï¸ è¯·å®ŒæˆOpenAIé…ç½®")
    
    else:
        st.sidebar.subheader("ğŸ”µ Google GenAIé…ç½®")
        
        # ä¼˜å…ˆä½¿ç”¨ state ä¸­é¢„åŠ è½½çš„ key
        api_key_from_storage = st.session_state.get("api_key_to_load")
        
        # Gemini APIå¯†é’¥è¾“å…¥
        gemini_api_key = st.sidebar.text_input(
            "Gemini API Key",
            type="password",
            value=api_key_from_storage or "",
            help="è¯·è¾“å…¥æ‚¨çš„ Google Gemini API å¯†é’¥"
        )
        
        if gemini_api_key:
            st.sidebar.success("âœ… Gemini APIå¯†é’¥å·²è®¾ç½®")
    
    # æ™ºèƒ½APIå¯†é’¥æç¤º
    st.sidebar.divider()
    
    # æ£€æŸ¥å½“å‰é…ç½®éœ€è¦å“ªäº›APIå¯†é’¥
    needs_gemini = False
    needs_openai = False
    
    # æ£€æŸ¥ä¸»APIæ¨¡å¼
    if st.session_state.api_mode == APIMode.GENAI:
        needs_gemini = True
    elif st.session_state.api_mode == APIMode.OPENAI:
        needs_openai = True
    
    # æ£€æŸ¥æœç´¢æ¨¡å¼
    search_mode = st.session_state.get("search_mode", "genai")
    if search_mode == "genai":
        needs_gemini = True
    elif search_mode == "openai":
        needs_openai = True
    
    # æ£€æŸ¥ä»»åŠ¡æ¨¡å‹é…ç½®
    for task_key, model_name in st.session_state.task_models.items():
        if model_name in AVAILABLE_MODELS:
            needs_gemini = True
        else:
            # è‡ªå®šä¹‰æ¨¡å‹ï¼Œå‡è®¾æ˜¯OpenAIå…¼å®¹
            needs_openai = True
    
    # æ˜¾ç¤ºAPIå¯†é’¥éœ€æ±‚æç¤º
    if needs_gemini or needs_openai:
        st.sidebar.markdown("**ğŸ”‘ APIå¯†é’¥éœ€æ±‚**")
        
        if needs_gemini:
            gemini_status = "âœ…" if st.session_state.get("api_key_to_load") else "âŒ"
            st.sidebar.text(f"{gemini_status} Gemini APIå¯†é’¥")
        
        if needs_openai:
            openai_status = "âœ…" if st.session_state.openai_config.get("api_key") else "âŒ"
            st.sidebar.text(f"{openai_status} OpenAIå…¼å®¹APIå¯†é’¥")
    
    return setup_model_configuration()


def setup_model_configuration():
    """è®¾ç½®æ¨¡å‹é…ç½®"""
    st.sidebar.divider()
    st.sidebar.subheader("ğŸ¯ æ¨¡å‹é…ç½®")
    
    # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    available_models = list(AVAILABLE_MODELS.keys())
    
    # æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹åˆ°å¯ç”¨åˆ—è¡¨
    for custom_model in st.session_state.custom_models:
        if custom_model["name"] not in available_models:
            available_models.append(custom_model["name"])
    
    # ä¸»æ¨¡å‹é€‰æ‹©
    main_model = st.sidebar.selectbox(
        "ä¸»è¦æ¨¡å‹",
        options=available_models,
        index=0 if st.session_state.model_name not in available_models else available_models.index(st.session_state.model_name),
        format_func=lambda x: AVAILABLE_MODELS.get(x, f"ğŸ”§ {x} (è‡ªå®šä¹‰)"),
        help="é€‰æ‹©ä¸»è¦ä½¿ç”¨çš„æ¨¡å‹"
    )
    
    # é«˜çº§æ¨¡å‹é…ç½®
    with st.sidebar.expander("ğŸ”§ é«˜çº§æ¨¡å‹é…ç½®", expanded=False):
        st.write("ä¸ºä¸åŒä»»åŠ¡é…ç½®ä¸“ç”¨æ¨¡å‹:")
        
        # æœç´¢æ¨¡å¼é…ç½®ï¼ˆç‰¹æ®Šå¤„ç†ï¼‰
        st.markdown("**ğŸ” æœç´¢é…ç½®**")
        search_mode = st.selectbox(
            "æœç´¢æ¨¡å¼",
            options=list(SEARCH_MODE_OPTIONS.keys()),
            index=list(SEARCH_MODE_OPTIONS.keys()).index(st.session_state.get("search_mode", "genai")),
            format_func=lambda x: SEARCH_MODE_OPTIONS[x],
            help="æœç´¢æ¨¡å¼ï¼šGenAIæ”¯æŒgroundingæœç´¢ï¼ŒOpenAIå…¼å®¹æ¨¡å¼æ— æœç´¢åŠŸèƒ½",
            key="search_mode_selector"
        )
        
        if search_mode != st.session_state.get("search_mode", "genai"):
            st.session_state.search_mode = search_mode
            st.session_state.config_changed = True
            save_config_to_storage()
        
        # æ ¹æ®æœç´¢æ¨¡å¼æ˜¾ç¤ºè­¦å‘Š
        if search_mode == "openai":
            st.warning("âš ï¸ OpenAIæ¨¡å¼ä¸‹æœç´¢åŠŸèƒ½å°†é™çº§åˆ°åŸºäºçŸ¥è¯†åº“çš„å›ç­”")
        elif search_mode == "genai":
            st.success("âœ… GenAIæ¨¡å¼æ”¯æŒå®Œæ•´çš„groundingæœç´¢åŠŸèƒ½")
        
        st.divider()
        st.write("ä»»åŠ¡æ¨¡å‹é…ç½®:")
        
        for task_key, task_name in TASK_MODEL_MAPPING.items():
            current_model = st.session_state.task_models.get(task_key, main_model)
            
            new_model = st.selectbox(
                task_name,
                options=available_models,
                index=available_models.index(current_model) if current_model in available_models else 0,
                format_func=lambda x: AVAILABLE_MODELS.get(x, f"ğŸ”§ {x} (è‡ªå®šä¹‰)"),
                key=f"task_model_{task_key}"
            )
            
            if new_model != st.session_state.task_models.get(task_key):
                st.session_state.task_models[task_key] = new_model
                st.session_state.config_changed = True
                save_config_to_storage()
    
    # è‡ªå®šä¹‰æ¨¡å‹ç®¡ç†
    with st.sidebar.expander("â• è‡ªå®šä¹‰æ¨¡å‹", expanded=False):
        st.write("æ·»åŠ OpenAIå…¼å®¹çš„è‡ªå®šä¹‰æ¨¡å‹:")
        
        with st.form("add_custom_model"):
            model_name = st.text_input("æ¨¡å‹åç§°", placeholder="gpt-4-custom")
            model_base_url = st.text_input("Base URL", value=st.session_state.openai_config["base_url"])
            supports_search = st.checkbox("æ”¯æŒæœç´¢", value=False)
            supports_tools = st.checkbox("æ”¯æŒå·¥å…·è°ƒç”¨", value=True)
            
            col1, col2 = st.columns(2)
            with col1:
                temperature = st.number_input("Temperature", min_value=0.0, max_value=2.0, value=0.3, step=0.1)
            with col2:
                max_tokens = st.number_input("Max Tokens", min_value=100, max_value=32000, value=4096, step=100)
            
            if st.form_submit_button("æ·»åŠ æ¨¡å‹"):
                if model_name and model_base_url:
                    custom_model = {
                        "name": model_name,
                        "base_url": model_base_url,
                        "supports_search": supports_search,
                        "supports_tools": supports_tools,
                        "default_params": {
                            "temperature": temperature,
                            "max_tokens": max_tokens
                        }
                    }
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing_names = [m["name"] for m in st.session_state.custom_models]
                    if model_name not in existing_names:
                        st.session_state.custom_models.append(custom_model)
                        st.session_state.config_changed = True
                        save_config_to_storage()
                        st.success(f"âœ… å·²æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹: {model_name}")
                        st.rerun()
                    else:
                        st.error("âŒ æ¨¡å‹åç§°å·²å­˜åœ¨")
                else:
                    st.error("âŒ è¯·å¡«å†™å®Œæ•´ä¿¡æ¯")
        
        # æ˜¾ç¤ºå·²æ·»åŠ çš„è‡ªå®šä¹‰æ¨¡å‹
        if st.session_state.custom_models:
            st.write("å·²æ·»åŠ çš„è‡ªå®šä¹‰æ¨¡å‹:")
            for i, model in enumerate(st.session_state.custom_models):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.text(f"ğŸ”§ {model['name']}")
                with col2:
                    if st.button("åˆ é™¤", key=f"del_model_{i}"):
                        st.session_state.custom_models.pop(i)
                        st.session_state.config_changed = True
                        save_config_to_storage()
                        st.rerun()
    
    return main_model


def setup_api_key():
    """è®¾ç½®APIå¯†é’¥å’Œæ¨¡å‹é€‰æ‹©ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
    model_name = setup_api_configuration()
    
    # è·å–APIå¯†é’¥
    if st.session_state.api_mode == APIMode.OPENAI:
        api_key = st.session_state.openai_config.get("api_key", "")
    else:
        api_key = st.session_state.get("api_key_to_load", "")
    
    if api_key:
        if validate_and_setup_engine(api_key, model_name):
            st.session_state.api_key_validated = True
            st.sidebar.success("âœ… APIé…ç½®æˆåŠŸ")
            
            # ä¿å­˜APIå¯†é’¥åˆ°localStorage
            localS = SafeLocalStorage()
            try:
                if st.session_state.api_mode != APIMode.OPENAI:
                    localS.setItem("api_key", api_key)
                    st.session_state.api_key_to_load = api_key
                    st.session_state.ls_api_key = api_key
            except Exception as e:
                st.sidebar.warning(f"âš ï¸ ä¿å­˜APIå¯†é’¥å¤±è´¥: {e}")
            
            # æ˜¾ç¤ºå½“å‰é…ç½®è¯¦æƒ…
            if st.session_state.research_engine:
                with st.sidebar.expander("ğŸ“‹ å½“å‰é…ç½®è¯¦æƒ…", expanded=False):
                    client_info = st.session_state.research_engine.get_client_info()
                    
                    st.text(f"ğŸ”„ APIæ¨¡å¼: {st.session_state.api_mode.value}")
                    st.text(f"ğŸ” æœç´¢å®¢æˆ·ç«¯: {client_info['search_client']['type']}")
                    st.text(f"ğŸ—ï¸ å·¥ä½œæµå®¢æˆ·ç«¯: {client_info['workflow_client']['type']}")
                    
                    if st.session_state.api_mode == APIMode.OPENAI:
                        st.text(f"ğŸŒ Base URL: {st.session_state.openai_config['base_url']}")
                    
                    st.divider()
                    st.text("ä»»åŠ¡æ¨¡å‹é…ç½®:")
                    for task_key, model_name in st.session_state.task_models.items():
                        task_name = TASK_MODEL_MAPPING[task_key]
                        st.text(f"  {task_name}: {model_name}")
            
            # Debugå¼€å…³
            st.sidebar.divider()
            st.sidebar.subheader("ğŸ› Debugæ¨¡å¼")
            
            debug_enabled = st.sidebar.checkbox(
                "å¯ç”¨è°ƒè¯•æ¨¡å¼",
                value=st.session_state.debug_enabled,
                help="å¯ç”¨åå°†è®°å½•æ‰€æœ‰APIè¯·æ±‚å’Œå“åº”åˆ°JSONæ–‡ä»¶ï¼Œç”¨äºè°ƒè¯•"
            )
            
            # é…ç½®ç®¡ç†
            st.sidebar.divider()
            st.sidebar.subheader("âš™ï¸ é…ç½®ç®¡ç†")
            
            col1, col2 = st.sidebar.columns(2)
            
            with col1:
                if st.button("ğŸ“¤ å¯¼å‡ºé…ç½®", help="å¯¼å‡ºå½“å‰é…ç½®åˆ°JSONæ–‡ä»¶"):
                    export_config()
            
            with col2:
                if st.button("ğŸ”„ é‡ç½®é…ç½®", help="é‡ç½®æ‰€æœ‰é…ç½®åˆ°é»˜è®¤å€¼"):
                    reset_config()
            
            # é…ç½®å¯¼å…¥
            uploaded_config = st.sidebar.file_uploader(
                "ğŸ“¥ å¯¼å…¥é…ç½®",
                type=['json'],
                help="ä¸Šä¼ ä¹‹å‰å¯¼å‡ºçš„é…ç½®æ–‡ä»¶"
            )
            
            if uploaded_config is not None:
                import_config(uploaded_config)
            
            if debug_enabled != st.session_state.debug_enabled:
                st.session_state.debug_enabled = debug_enabled
                if debug_enabled:
                    enable_debug("debug_logs")
                    st.sidebar.success("ğŸ› Debugæ¨¡å¼å·²å¯ç”¨")
                    st.sidebar.info("ğŸ“ æ—¥å¿—å°†ä¿å­˜åˆ° debug_logs/ ç›®å½•")
                else:
                    disable_debug()
                    st.sidebar.info("ğŸ› Debugæ¨¡å¼å·²ç¦ç”¨")
            
            if debug_enabled:
                debug_logger = get_debug_logger()
                if debug_logger.current_session:
                    st.sidebar.text(f"ğŸ“ ä¼šè¯ID: {debug_logger.current_session}")
                    
                    # æ˜¾ç¤ºä¼šè¯æ‘˜è¦
                    summary = debug_logger.get_session_summary()
                    if summary:
                        with st.sidebar.expander("ğŸ“Š Debugç»Ÿè®¡", expanded=False):
                            # APIè¯·æ±‚ç»Ÿè®¡
                            api_stats = summary.get("api_requests", {})
                            st.markdown("**ğŸ”— APIè¯·æ±‚ç»Ÿè®¡**")
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("æ€»è¯·æ±‚", api_stats.get("total", 0))
                                st.metric("æˆåŠŸ", api_stats.get("successful", 0))
                            with col2:
                                st.metric("å¤±è´¥", api_stats.get("failed", 0))
                            
                            # æŒ‰ç±»å‹ç»Ÿè®¡
                            by_type = api_stats.get("by_type", {})
                            if by_type:
                                st.markdown("**è¯·æ±‚ç±»å‹åˆ†å¸ƒ:**")
                                for req_type, count in by_type.items():
                                    st.text(f"â€¢ {req_type}: {count}")
                            
                            # æŒ‰æ¨¡å‹ç»Ÿè®¡
                            by_model = api_stats.get("by_model", {})
                            if by_model:
                                st.markdown("**æ¨¡å‹ä½¿ç”¨åˆ†å¸ƒ:**")
                                for model, count in by_model.items():
                                    st.text(f"â€¢ {model}: {count}")
                            
                            st.divider()
                            
                            # æœç´¢ç»Ÿè®¡
                            search_stats = summary.get("searches", {})
                            st.markdown("**ğŸ” æœç´¢ç»Ÿè®¡**")
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("æ€»æœç´¢", search_stats.get("total", 0))
                                st.metric("æˆåŠŸ", search_stats.get("successful", 0))
                            with col2:
                                st.metric("å¤±è´¥", search_stats.get("failed", 0))
                                st.metric("æ€»å¼•ç”¨", search_stats.get("total_citations", 0))
                            
                            st.divider()
                            
                            # å·¥ä½œæµç»Ÿè®¡
                            workflow_stats = summary.get("workflow", {})
                            st.markdown("**âš™ï¸ å·¥ä½œæµç»Ÿè®¡**")
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("æ€»æ­¥éª¤", workflow_stats.get("total_steps", 0))
                                st.metric("å·²å®Œæˆ", workflow_stats.get("completed_steps", 0))
                            with col2:
                                st.metric("å¤±è´¥", workflow_stats.get("failed_steps", 0))
                            
                            # æ­¥éª¤åºåˆ—
                            step_sequence = workflow_stats.get("step_sequence", [])
                            if step_sequence:
                                st.markdown("**æ‰§è¡Œåºåˆ—:**")
                                for i, step in enumerate(step_sequence, 1):
                                    st.text(f"{i}. {step}")
                            
                            # æ­¥éª¤è€—æ—¶
                            step_durations = workflow_stats.get("step_durations", {})
                            if step_durations:
                                st.markdown("**æ­¥éª¤è€—æ—¶:**")
                                for step, duration in step_durations.items():
                                    if duration > 0:
                                        st.text(f"â€¢ {step}: {duration:.2f}s")
                            
                            st.divider()
                            
                            # ä¼šè¯ä¿¡æ¯
                            session_duration = summary.get("session_duration", 0)
                            if session_duration > 0:
                                st.metric("ä¼šè¯æ—¶é•¿", f"{session_duration:.2f}s")
                            
                            # é”™è¯¯ç»Ÿè®¡
                            error_stats = summary.get("errors", {})
                            if error_stats.get("total", 0) > 0:
                                st.markdown("**âŒ é”™è¯¯ç»Ÿè®¡**")
                                st.metric("é”™è¯¯æ€»æ•°", error_stats.get("total", 0))
                                by_error_type = error_stats.get("by_type", {})
                                if by_error_type:
                                    for error_type, count in by_error_type.items():
                                        st.text(f"â€¢ {error_type}: {count}")
                    
                    # ç«‹å³ä¿å­˜æŒ‰é’®
                    if st.sidebar.button("ğŸ’¾ ä¿å­˜Debugæ—¥å¿—"):
                        debug_logger.save_now()
                        st.sidebar.success("âœ… Debugæ—¥å¿—å·²ä¿å­˜")
                    
                    # æŸ¥çœ‹è¯¦ç»†æ—¥å¿—æŒ‰é’®
                    if st.sidebar.button("ğŸ“‹ æŸ¥çœ‹è¯¦ç»†æ—¥å¿—"):
                        st.session_state.show_debug_details = True
        else:
            st.session_state.api_key_validated = False
            st.sidebar.error("âŒ APIå¯†é’¥éªŒè¯å¤±è´¥")
    
    return st.session_state.api_key_validated


def display_real_time_progress():
    """æ˜¾ç¤ºå®æ—¶è¿›åº¦"""
    if st.session_state.is_researching and st.session_state.progress_messages:
        
        # æ˜¾ç¤ºå½“å‰æ­¥éª¤
        if st.session_state.current_step:
            st.markdown(f'''
            <div class="thinking-box">
                ğŸ¤” <strong>{st.session_state.current_step}</strong>
            </div>
            ''', unsafe_allow_html=True)
        
        # æ˜¾ç¤ºè¿›åº¦æ¡
        if st.session_state.progress_percentage > 0:
            st.progress(st.session_state.progress_percentage / 100)
        
        # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
        with st.expander("ğŸ“ æ€è€ƒè¿‡ç¨‹", expanded=True):
            for i, msg in enumerate(st.session_state.progress_messages, 1):
                st.markdown(f'<div class="progress-step">{i}. {msg}</div>', 
                          unsafe_allow_html=True)


def run_research_in_background(
    engine, user_query, max_search_rounds, effort_level, num_search_queries, q, stop_event
):
    """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œç ”ç©¶ä»»åŠ¡"""
    try:
        # ä¸ºè¿™ä¸ªçº¿ç¨‹åˆ›å»ºä¸€ä¸ªæ–°çš„äº‹ä»¶å¾ªç¯
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        def progress_callback(message, percentage):
            if stop_event.is_set():
                engine.stop_research()
                raise Exception("ç”¨æˆ·è¯·æ±‚åœæ­¢")
            q.put({"type": "progress", "message": message, "percentage": percentage})

        def step_callback(message):
            if stop_event.is_set():
                engine.stop_research()
                raise Exception("ç”¨æˆ·è¯·æ±‚åœæ­¢")
            q.put({"type": "step", "message": message})
            
        def error_callback(message):
            q.put({"type": "error", "message": message})

        engine.set_callbacks(
            progress_callback=progress_callback,
            step_callback=step_callback,
            error_callback=error_callback,
        )
        
        # é‡ç½®å¼•æ“çš„åœæ­¢æ ‡è®°
        engine.reset_stop_flag()

        # è¿è¡Œå¼‚æ­¥ç ”ç©¶æ–¹æ³•
        results = loop.run_until_complete(
            engine.research(user_query, max_search_rounds, effort_level, num_search_queries)
        )
        q.put({"type": "result", "data": results})
        
    except Exception as e:
        if "ç”¨æˆ·è¯·æ±‚åœæ­¢" not in str(e):
            error_msg = f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}"
            q.put({"type": "error", "message": error_msg})
        # å¦‚æœæ˜¯ç”¨æˆ·åœæ­¢ï¼Œå›è°ƒä¸­å·²ç»å¤„ç†äº†ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤å‘é€æ¶ˆæ¯


def research_interface():
    """ç ”ç©¶ä¸»ç•Œé¢"""
    st.title("ğŸ” DeepSearch - æ™ºèƒ½æ·±åº¦ç ”ç©¶åŠ©æ‰‹")
    st.markdown("### æ™ºèƒ½æ·±åº¦ç ”ç©¶åŠ©æ‰‹")
    
    # åˆå§‹åŒ–çº¿ç¨‹æ± æ‰§è¡Œå™¨
    if "executor" not in st.session_state:
        st.session_state.executor = concurrent.futures.ThreadPoolExecutor(max_workers=2)

    # æŸ¥è¯¢è¾“å…¥
    user_query = st.text_area(
        "è¯·è¾“å…¥æ‚¨çš„ç ”ç©¶é—®é¢˜:",
        height=100,
        placeholder="ä¾‹å¦‚: åˆ†æ2024å¹´äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿...",
        help="è¯·æè¿°æ‚¨æƒ³è¦æ·±å…¥ç ”ç©¶çš„é—®é¢˜æˆ–ä¸»é¢˜",
        disabled=st.session_state.is_researching
    )
    
    # ç ”ç©¶å‚æ•°è®¾ç½®
    col1, col2 = st.columns(2)
    with col1:
        effort_level = st.selectbox(
            "ç ”ç©¶å¼ºåº¦",
            ["low", "medium", "high"],
            index=1,
            format_func=lambda x: {"low": "ğŸŸ¢ ä½å¼ºåº¦", "medium": "ğŸŸ¡ ä¸­å¼ºåº¦", "high": "ğŸ”´ é«˜å¼ºåº¦"}[x],
            help="ä½å¼ºåº¦: 1è½®Ã—3æŸ¥è¯¢, ä¸­å¼ºåº¦: 3è½®Ã—5æŸ¥è¯¢, é«˜å¼ºåº¦: 5è½®Ã—10æŸ¥è¯¢",
            disabled=st.session_state.is_researching
        )
    
    with col2:
        # æ ¹æ®å¼ºåº¦æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        effort_configs = {
            "low": {"rounds": "1è½®(æœ€å¤š3è½®)", "queries": 3, "time": "1-5åˆ†é’Ÿ"},
            "medium": {"rounds": 3, "queries": 5, "time": "4-10åˆ†é’Ÿ"},
            "high": {"rounds": 5, "queries": 10, "time": "8-20åˆ†é’Ÿ"}
        }
        config = effort_configs[effort_level]
        
        st.info(f"""
        ğŸ“Š **å½“å‰é…ç½®**
        - ğŸ”„ æœç´¢è½®æ•°: {config['rounds']}è½®
        - ğŸ” æ¯è½®æŸ¥è¯¢: {config['queries']}ä¸ª
        - â±ï¸ é¢„è®¡æ—¶é—´: {config['time']}
        """)
        
        # è®¾ç½®é»˜è®¤å€¼ï¼Œä½†å…è®¸ç”¨æˆ·åœ¨é«˜çº§è®¾ç½®ä¸­è¦†ç›–
        default_max_rounds = {"low": 3, "medium": 3, "high": 5}[effort_level]
        max_search_rounds = default_max_rounds
        num_search_queries = config['queries']
        
        with st.expander("âš™ï¸ é«˜çº§è®¾ç½®", expanded=False):
            max_search_rounds = st.slider(
                "è‡ªå®šä¹‰æœ€å¤§æœç´¢è½®æ•°", 1, 10, default_max_rounds,
                help="è¦†ç›–é»˜è®¤çš„æœç´¢è½®æ•°è®¾ç½®",
                disabled=st.session_state.is_researching
            )
            
            num_search_queries = st.slider(
                "è‡ªå®šä¹‰æ¯è½®æŸ¥è¯¢æ•°é‡", 1, 15, config['queries'],
                help="è¦†ç›–é»˜è®¤çš„æ¯è½®æŸ¥è¯¢æ•°é‡",
                disabled=st.session_state.is_researching
            )
            
            st.info(f"ğŸ’¡ **è¯´æ˜**: ä½å¼ºåº¦é»˜è®¤1è½®æœç´¢ï¼Œä¿¡æ¯ä¸è¶³æ—¶è‡ªåŠ¨è¡¥å……ï¼Œæœ€å¤š3è½®")
    
    # å¼€å§‹/åœæ­¢ç ”ç©¶æŒ‰é’®
    if not st.session_state.is_researching:
        if st.button("ğŸš€ å¼€å§‹ç ”ç©¶", type="primary", disabled=not user_query.strip()):
            if not st.session_state.research_engine:
                st.error("ç ”ç©¶å¼•æ“æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
            else:
                # é˜²æ­¢é‡å¤æäº¤ï¼šæ£€æŸ¥æ˜¯å¦å·²æœ‰ä»»åŠ¡åœ¨è¿è¡Œ
                if "current_task_future" in st.session_state and not st.session_state.current_task_future.done():
                    st.warning("âš ï¸ å·²æœ‰ç ”ç©¶ä»»åŠ¡åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆæˆ–å…ˆåœæ­¢å½“å‰ä»»åŠ¡")
                    return
                
                st.session_state.is_researching = True
                st.session_state.research_complete = False
                st.session_state.research_error = None
                st.session_state.progress_messages = ["ğŸš€ ç ”ç©¶ä»»åŠ¡å·²å¯åŠ¨..."]
                st.session_state.current_step = "åˆå§‹åŒ–..."
                st.session_state.progress_percentage = 0
                # æ³¨æ„ï¼šä¸è¦æ¸…ç©ºresearch_resultsï¼Œä¿ç•™å†å²è®°å½•
                st.session_state.just_completed = False
                st.session_state.research_started = True  # æ·»åŠ å¯åŠ¨æ ‡è®°

                q = queue.Queue()
                stop_event = threading.Event()
                st.session_state.queue = q
                st.session_state.stop_event = stop_event

                st.session_state.current_task_future = st.session_state.executor.submit(
                    run_research_in_background,
                    st.session_state.research_engine,
                    user_query,
                    max_search_rounds,
                    effort_level,
                    num_search_queries,
                    q,
                    stop_event,
                )
                st.rerun()
    else:
        if st.button("â¹ï¸ åœæ­¢ç ”ç©¶", type="secondary"):
            if "stop_event" in st.session_state:
                st.session_state.stop_event.set()
            
            # ç«‹å³é‡ç½®ç ”ç©¶çŠ¶æ€ï¼Œé˜²æ­¢é‡å¤æäº¤
            st.session_state.is_researching = False
            st.session_state.research_started = False
            st.session_state.current_step = "å·²åœæ­¢"
            st.session_state.progress_messages.append("ğŸ›‘ ç”¨æˆ·æ‰‹åŠ¨åœæ­¢ç ”ç©¶")
            
            # ç­‰å¾…åå°ä»»åŠ¡å®Œæˆ
            if "current_task_future" in st.session_state:
                try:
                    # ç»™åå°ä»»åŠ¡ä¸€äº›æ—¶é—´æ¥å“åº”åœæ­¢ä¿¡å·
                    st.session_state.current_task_future.result(timeout=2)
                except:
                    pass  # å¿½ç•¥è¶…æ—¶æˆ–å…¶ä»–å¼‚å¸¸
            
            st.rerun()

    # ç ”ç©¶è¿›è¡Œä¸­ï¼Œå¤„ç†é˜Ÿåˆ—æ›´æ–°
    if st.session_state.is_researching:
        display_real_time_progress()

        if "queue" in st.session_state:
            try:
                while not st.session_state.queue.empty():
                    item = st.session_state.queue.get_nowait()
                    if item["type"] == "progress":
                        msg = f"[{item['percentage']:.1f}%] {item['message']}"
                        st.session_state.progress_messages.append(msg)
                        st.session_state.progress_percentage = item["percentage"]
                    elif item["type"] == "step":
                        st.session_state.current_step = item["message"]
                        st.session_state.progress_messages.append(f"âš¡ {item['message']}")
                    elif item["type"] == "result":
                        st.session_state.is_researching = False
                        st.session_state.research_complete = True
                        st.session_state.current_task = item["data"]
                        st.session_state.research_results.append(item["data"])
                        st.session_state.just_completed = True
                        
                        # ä¿å­˜åˆ°LocalStorage
                        try:
                            localS = SafeLocalStorage()
                            serializable_results = json_serializable(st.session_state.research_results)
                            # è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                            json_string = json.dumps(serializable_results, ensure_ascii=False)
                            success = localS.setItem("research_results", json_string)
                            if success:
                                # æ›´æ–°ç¼“å­˜
                                st.session_state.ls_research_results = json_string
                            else:
                                st.warning("âš ï¸ ä¿å­˜å†å²è®°å½•åˆ°LocalStorageå¤±è´¥")
                        except Exception as e:
                            st.warning(f"âš ï¸ ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")
                            import traceback
                            st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

                    elif item["type"] == "error":
                        st.session_state.is_researching = False
                        st.session_state.research_error = item["message"]
                    elif item["type"] == "info": # ç”¨äºå¤„ç†ç”¨æˆ·åœæ­¢ç­‰æƒ…å†µ
                        st.session_state.is_researching = False
                        st.info(item["message"])

                # å¦‚æœä»åœ¨ç ”ç©¶ä¸­ï¼Œå®‰æ’ä¸‹ä¸€æ¬¡åˆ·æ–°
                if st.session_state.is_researching:
                    time.sleep(0.1)
                    st.rerun()
                elif st.session_state.just_completed: # ç ”ç©¶åˆšåˆšç»“æŸï¼Œåˆ·æ–°ä¸€æ¬¡ä»¥æ˜¾ç¤ºæœ€ç»ˆç»“æœ
                    st.rerun()
            except queue.Empty:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œæ£€æŸ¥åå°ä»»åŠ¡æ˜¯å¦ä»åœ¨è¿è¡Œ
                if st.session_state.is_researching:
                    future = st.session_state.get("current_task_future")
                    if future and future.done():
                        # ä»»åŠ¡å·²ç»“æŸï¼Œä½†é˜Ÿåˆ—ä¸­æ²¡æœ‰æ¶ˆæ¯ï¼Œè¯´æ˜å¯èƒ½å‘ç”Ÿæ„å¤–
                        try:
                            # å°è¯•è·å–ç»“æœï¼Œè¿™ä¼šé‡æ–°å¼•å‘åœ¨çº¿ç¨‹ä¸­å‘ç”Ÿçš„ä»»ä½•å¼‚å¸¸
                            future.result() 
                            # å¦‚æœæ²¡æœ‰å¼‚å¸¸ï¼Œä½†èµ°åˆ°äº†è¿™é‡Œï¼Œè¯´æ˜é€»è¾‘æœ‰é—®é¢˜
                            st.session_state.research_error = "ç ”ç©¶æ„å¤–ç»ˆæ­¢ï¼Œä½†æœªæŠ¥å‘Šæ˜ç¡®é”™è¯¯ã€‚"
                        except Exception as e:
                            # æ•è·åˆ°åå°ä»»åŠ¡çš„å¼‚å¸¸
                            st.session_state.research_error = f"ç ”ç©¶ä»»åŠ¡åœ¨åå°å‘ç”Ÿé”™è¯¯: {e}"
                        
                        st.session_state.is_researching = False
                        st.rerun()
                    else:
                        # ä»»åŠ¡ä»åœ¨è¿è¡Œï¼Œé˜Ÿåˆ—ä¸ºç©ºæ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­è½®è¯¢
                        time.sleep(0.1)
                        st.rerun()

    # æ˜¾ç¤ºå†å²ç ”ç©¶ç»“æœ
    if st.session_state.research_results:
        # å¦‚æœæœ‰åˆšå®Œæˆçš„ç ”ç©¶ï¼Œæ˜¾ç¤ºæˆåŠŸæç¤º
        if st.session_state.just_completed:
            st.success("ğŸ‰ ç ”ç©¶å®Œæˆï¼")
            st.session_state.just_completed = False # é‡ç½®æ ‡è®°ï¼Œé¿å…é‡å¤æ˜¾ç¤º
        
        st.markdown("---")
        st.subheader("ğŸ“œ ç ”ç©¶å†å²è®°å½•")
        for i, result in enumerate(reversed(st.session_state.research_results)):
            task_id = result.get("task_id", f"history_{i}")
            # ä»task_idä¸­æå–æ—¶é—´æˆ³ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å½“å‰æ—¶é—´
            try:
                if task_id.startswith("task_") and len(task_id) >= 20:
                    timestamp_str = task_id[5:20]  # æå– YYYYMMDD_HHMMSS éƒ¨åˆ†
                    timestamp = datetime.strptime(timestamp_str, "%Y%m%d_%H%M%S")
                    time_display = timestamp.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    time_display = "æœªçŸ¥æ—¶é—´"
            except:
                time_display = "æœªçŸ¥æ—¶é—´"
            
            with st.expander(f"**{result.get('user_query', 'æœªçŸ¥æŸ¥è¯¢')}** - {time_display} ({task_id[:20]})", expanded=(i==0)):
                if result.get("success"):
                    display_final_answer(result, index=i)
                    display_search_results(result)
                    display_task_analysis(result.get("workflow_analysis"), result.get("task_id"))
                else:
                    st.error(f"ç ”ç©¶å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

    # å¦‚æœæœ‰é”™è¯¯ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
    if st.session_state.research_error and not st.session_state.is_researching:
        st.error(f"âŒ ç ”ç©¶å¤±è´¥: {st.session_state.research_error}")
    
    # æ˜¾ç¤ºè¯¦ç»†Debugæ—¥å¿—
    if st.session_state.get("show_debug_details", False):
        st.markdown("---")
        st.subheader("ğŸ› è¯¦ç»†Debugæ—¥å¿—")
        
        from utils.debug_logger import get_debug_logger
        debug_logger = get_debug_logger()
        
        if debug_logger.enabled and debug_logger.session_data:
            # åˆ›å»ºæ ‡ç­¾é¡µ
            tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“¤ APIè¯·æ±‚", "ğŸ” æœç´¢ç»“æœ", "âš™ï¸ å·¥ä½œæµæ­¥éª¤", "âŒ é”™è¯¯æ—¥å¿—", "ğŸ“Š ä¼šè¯ä¿¡æ¯"])
            
            with tab1:
                st.markdown("### APIè¯·æ±‚è¯¦æƒ…")
                api_requests = debug_logger.session_data.get("api_requests", [])
                if api_requests:
                    for i, req in enumerate(api_requests):
                        with st.expander(f"è¯·æ±‚ {i+1}: {req.get('request_type', 'unknown')} - {req.get('context', '')}", expanded=False):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.text(f"æ—¶é—´: {req.get('timestamp', 'N/A')}")
                                st.text(f"è¯·æ±‚ID: {req.get('request_id', 'N/A')}")
                                st.text(f"æ¨¡å‹: {req.get('model', 'N/A')}")
                                st.text(f"ç±»å‹: {req.get('request_type', 'N/A')}")
                                st.text(f"ä¸Šä¸‹æ–‡: {req.get('context', 'N/A')}")
                            with col2:
                                st.text(f"Prompté•¿åº¦: {req.get('full_prompt_length', 0)}")
                                response = req.get('response', {})
                                if response:
                                    st.text(f"å“åº”é•¿åº¦: {response.get('full_response_length', 0)}")
                                    st.text(f"è€—æ—¶: {response.get('duration', 0):.2f}s")
                                    st.text(f"çŠ¶æ€: {response.get('status', 'N/A')}")
                            
                            # æ˜¾ç¤ºå®Œæ•´promptå’Œå“åº”
                            if st.checkbox(f"æ˜¾ç¤ºå®Œæ•´å†…å®¹ - è¯·æ±‚{i+1}", key=f"show_full_req_{i}"):
                                st.text_area("å®Œæ•´Prompt:", req.get('full_prompt', ''), height=200, key=f"prompt_{i}")
                                if response and response.get('full_response'):
                                    st.text_area("å®Œæ•´å“åº”:", response.get('full_response', ''), height=200, key=f"response_{i}")
                else:
                    st.info("æš‚æ— APIè¯·æ±‚è®°å½•")
            
            with tab2:
                st.markdown("### æœç´¢ç»“æœè¯¦æƒ…")
                search_results = debug_logger.session_data.get("search_results", [])
                if search_results:
                    for i, search in enumerate(search_results):
                        with st.expander(f"æœç´¢ {i+1}: {search.get('query', 'unknown')[:50]}...", expanded=False):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.text(f"æ—¶é—´: {search.get('timestamp', 'N/A')}")
                                st.text(f"æŸ¥è¯¢: {search.get('query', 'N/A')}")
                                st.text(f"ç±»å‹: {search.get('search_type', 'N/A')}")
                                st.text(f"æˆåŠŸ: {search.get('success', False)}")
                            with col2:
                                st.text(f"å†…å®¹é•¿åº¦: {search.get('content_length', 0)}")
                                st.text(f"å¼•ç”¨æ•°: {search.get('citations_count', 0)}")
                                st.text(f"URLæ•°: {search.get('urls_count', 0)}")
                                st.text(f"è€—æ—¶: {search.get('duration', 0):.2f}s")
                            
                            # æ˜¾ç¤ºå®Œæ•´æœç´¢ç»“æœ
                            if st.checkbox(f"æ˜¾ç¤ºå®Œæ•´ç»“æœ - æœç´¢{i+1}", key=f"show_full_search_{i}"):
                                full_result = search.get('full_result', {})
                                st.json(full_result)
                else:
                    st.info("æš‚æ— æœç´¢è®°å½•")
            
            with tab3:
                st.markdown("### å·¥ä½œæµæ­¥éª¤è¯¦æƒ…")
                workflow_steps = debug_logger.session_data.get("workflow_steps", [])
                if workflow_steps:
                    for i, step in enumerate(workflow_steps):
                        step_name = step.get('step_name', 'unknown')
                        step_status = step.get('step_status', 'unknown')
                        duration = step.get('duration', 0)
                        
                        status_icon = {"completed": "âœ…", "running": "ğŸ”„", "failed": "âŒ", "info": "â„¹ï¸", "decision": "ğŸ¤”"}.get(step_status, "â“")
                        
                        with st.expander(f"æ­¥éª¤ {i+1}: {status_icon} {step_name} [{duration:.2f}s]", expanded=False):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.text(f"æ—¶é—´: {step.get('timestamp', 'N/A')}")
                                st.text(f"æ­¥éª¤å: {step_name}")
                                st.text(f"çŠ¶æ€: {step_status}")
                                if step.get('step_index') is not None:
                                    st.text(f"æ­¥éª¤ç´¢å¼•: {step.get('step_index', 0) + 1}/{step.get('total_steps', 0)}")
                            with col2:
                                st.text(f"è€—æ—¶: {duration:.2f}s")
                                if step.get('error_message'):
                                    st.text(f"é”™è¯¯: {step.get('error_message', '')}")
                            
                            # æ˜¾ç¤ºè¾“å…¥è¾“å‡ºæ•°æ®
                            if st.checkbox(f"æ˜¾ç¤ºè¯¦ç»†æ•°æ® - æ­¥éª¤{i+1}", key=f"show_step_data_{i}"):
                                if step.get('full_input'):
                                    st.text("è¾“å…¥æ•°æ®:")
                                    st.json(step.get('input_summary', {}))
                                if step.get('full_output'):
                                    st.text("è¾“å‡ºæ•°æ®:")
                                    st.json(step.get('output_summary', {}))
                else:
                    st.info("æš‚æ— å·¥ä½œæµæ­¥éª¤è®°å½•")
            
            with tab4:
                st.markdown("### é”™è¯¯æ—¥å¿—")
                errors = debug_logger.session_data.get("errors", [])
                if errors:
                    for i, error in enumerate(errors):
                        with st.expander(f"é”™è¯¯ {i+1}: {error.get('error_type', 'unknown')}", expanded=False):
                            st.text(f"æ—¶é—´: {error.get('timestamp', 'N/A')}")
                            st.text(f"ç±»å‹: {error.get('error_type', 'N/A')}")
                            st.text(f"æ¶ˆæ¯: {error.get('error_message', 'N/A')}")
                            
                            if error.get('context'):
                                st.text("ä¸Šä¸‹æ–‡:")
                                st.json(error.get('context', {}))
                            
                            if error.get('stacktrace'):
                                st.text("å †æ ˆè·Ÿè¸ª:")
                                st.code(error.get('stacktrace', ''), language='python')
                else:
                    st.info("æš‚æ— é”™è¯¯è®°å½•")
            
            with tab5:
                st.markdown("### ä¼šè¯ä¿¡æ¯")
                session_info = debug_logger.session_data.get("session_info", {})
                if session_info:
                    st.json(session_info)
                
                st.markdown("### ç ”ç©¶ç»“æœ")
                research_results = debug_logger.session_data.get("research_results", [])
                if research_results:
                    for i, result in enumerate(research_results):
                        with st.expander(f"ç ”ç©¶ç»“æœ {i+1}: {result.get('user_query', 'unknown')[:50]}...", expanded=False):
                            st.text(f"æ—¶é—´: {result.get('timestamp', 'N/A')}")
                            st.text(f"ç”¨æˆ·æŸ¥è¯¢: {result.get('user_query', 'N/A')}")
                            st.text(f"ç­”æ¡ˆé•¿åº¦: {result.get('final_answer_length', 0)}")
                            st.text(f"æˆåŠŸ: {result.get('success', False)}")
                            
                            if result.get('metadata'):
                                st.text("å…ƒæ•°æ®:")
                                st.json(result.get('metadata', {}))
                else:
                    st.info("æš‚æ— ç ”ç©¶ç»“æœè®°å½•")
        else:
            st.info("Debugæ¨¡å¼æœªå¯ç”¨æˆ–æš‚æ— æ•°æ®")
        
        # å…³é—­æŒ‰é’®
        if st.button("âŒ å…³é—­è¯¦ç»†æ—¥å¿—"):
            st.session_state.show_debug_details = False
            st.rerun()


def export_results():
    """å¯¼å‡ºç ”ç©¶ç»“æœ"""
    if not st.session_state.research_results:
        st.sidebar.warning("æ²¡æœ‰å¯å¯¼å‡ºçš„ç ”ç©¶ç»“æœã€‚")
        return

    st.sidebar.subheader("ğŸ“¤ å¯¼å‡ºç»“æœ")

    # é»˜è®¤å¯¼å‡ºæœ€è¿‘ä¸€æ¬¡çš„ç»“æœ
    latest_result = st.session_state.research_results[-1]
    
    try:
        # ä½¿ç”¨ json_serializable å¤„ç†æšä¸¾ç­‰ç‰¹æ®Šç±»å‹
        json_data = json.dumps(json_serializable(latest_result), indent=4, ensure_ascii=False)
        
        task_id = latest_result.get("task_id", "research_results")
        file_name = f"{task_id}.json"

        st.sidebar.download_button(
            label="ğŸ“¥ ä¸‹è½½JSONæ ¼å¼ç»“æœ",
            data=json_data,
            file_name=file_name,
            mime="application/json",
            help="å°†æœ€è¿‘ä¸€æ¬¡çš„ç ”ç©¶ç»“æœå¯¼å‡ºä¸ºJSONæ–‡ä»¶"
        )

        markdown_content = create_markdown_content(latest_result)
        md_file_name = f"{task_id}.md"

        st.sidebar.download_button(
            label="ğŸ“ ä¸‹è½½Markdownæ ¼å¼æŠ¥å‘Š",
            data=markdown_content,
            file_name=md_file_name,
            mime="text/markdown",
            help="å°†æœ€è¿‘ä¸€æ¬¡çš„ç ”ç©¶ç»“æœå¯¼å‡ºä¸ºMarkdownæ–‡ä»¶"
        )
    except Exception as e:
        st.sidebar.error(f"å¯¼å‡ºå¤±è´¥: {e}")


def sidebar_content():
    """ä¾§è¾¹æ å†…å®¹"""
    st.sidebar.title("DeepSearch")

    # APIå¯†é’¥å’Œæ¨¡å‹é…ç½®
    if not setup_api_key():
        st.warning("âš ï¸ è¯·å…ˆé…ç½®æœ‰æ•ˆçš„ Gemini API å¯†é’¥")
        st.markdown("""
        ### å¦‚ä½•è·å– Gemini API å¯†é’¥:
        1. è®¿é—® [Google AI Studio](https://makersuite.google.com/app/apikey)
        2. åˆ›å»ºæ–°çš„ API å¯†é’¥
        3. å°†å¯†é’¥è¾“å…¥åˆ°å·¦ä¾§é…ç½®æ ä¸­
        
        ### é…ç½®æ–‡ä»¶æ–¹å¼:
        åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.streamlit/secrets.toml` æ–‡ä»¶:
        ```toml
        [secrets]
        GEMINI_API_KEY = "your_api_key_here"
        ```
        """)
        return # å¦‚æœæ²¡æœ‰æœ‰æ•ˆAPIå¯†é’¥ï¼Œåˆ™ä¸æ˜¾ç¤ºä¾§è¾¹æ çš„å…¶ä½™éƒ¨åˆ†

    st.sidebar.divider()
    
    # ä¼šè¯ç»Ÿè®¡
    st.sidebar.markdown("### ğŸ“Š ä¼šè¯ç»Ÿè®¡")
    if st.session_state.research_engine:
        stats = st.session_state.research_engine.state_manager.get_session_statistics()
        
        col1, col2 = st.sidebar.columns(2)
        with col1:
            st.metric("æ€»ä»»åŠ¡æ•°", stats.get("total_tasks", 0))
            st.metric("æ€»æœç´¢æ•°", stats.get("total_searches", 0))
        with col2:
            st.metric("æˆåŠŸä»»åŠ¡", stats.get("successful_tasks", 0))
            session_duration = stats.get("session_duration", 0)
            st.metric("ä¼šè¯æ—¶é•¿", f"{session_duration/60:.1f}åˆ†é’Ÿ")

    # å¯¼å‡ºç»“æœ
    if st.session_state.research_results:
        st.sidebar.divider()
        export_results()

    st.sidebar.divider()

    # æ¸…ç©ºä¼šè¯æŒ‰é’®
    if st.sidebar.button("ğŸ—‘ï¸ æ¸…ç©ºä¼šè¯", disabled=st.session_state.is_researching):
        if st.session_state.research_engine:
            st.session_state.research_engine.clear_session()
        
        # æ¸…é™¤LocalStorageä¸­çš„ç ”ç©¶ç»“æœï¼Œä½†ä¿ç•™API key
        localS = SafeLocalStorage()
        localS.removeItem("research_results")

        # é‡ç½®æ‰€æœ‰çŠ¶æ€
        keys_to_reset = [
            "research_results", "current_task", "progress_messages",
            "is_researching", "research_complete", "research_error",
            "current_step", "progress_percentage", "research_started",
            "just_completed", "show_markdown_preview", "history_loaded",
            "first_load_message_shown", "ls_research_results", "ls_api_key"
        ]
        for key in keys_to_reset:
            if key in st.session_state:
                if isinstance(st.session_state[key], list):
                    st.session_state[key] = []
                elif isinstance(st.session_state[key], bool):
                    st.session_state[key] = False
                else:
                    st.session_state[key] = None
        
        if "current_research_id" in st.session_state:
            del st.session_state.current_research_id
        
        st.sidebar.success("ä¼šè¯å·²æ¸…ç©º")
        st.rerun()


def main():
    """ä¸»å‡½æ•°"""
    # æœ€é‡è¦ï¼šé¦–å…ˆåˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    initialize_session_state()
    
    # å»¶è¿ŸåŠ è½½å†å²è®°å½•ï¼ˆç¡®ä¿LocalStorageå·²å‡†å¤‡å¥½ï¼‰
    if "history_loaded" not in st.session_state:
        st.session_state.history_loaded = False
    
    if not st.session_state.history_loaded:
        try:
            localS = SafeLocalStorage()
            
            # ä½¿ç”¨session stateç¼“å­˜LocalStorageçš„å€¼ï¼Œé¿å…é‡å¤è°ƒç”¨
            if "ls_research_results" not in st.session_state:
                initial_results = localS.getItem("research_results")
                st.session_state.ls_research_results = initial_results
                # è°ƒè¯•ä¿¡æ¯
                if st.session_state.get("debug_enabled", False):
                    st.info(f"ğŸ” ä»LocalStorageåŠ è½½: {type(initial_results)} = {str(initial_results)[:100]}...")
            else:
                initial_results = st.session_state.ls_research_results
            
            # åªæœ‰å½“LocalStorageè¿”å›æœ‰æ•ˆæ•°æ®ä¸”å½“å‰æ²¡æœ‰å†å²è®°å½•æ—¶æ‰åŠ è½½
            if (initial_results and 
                initial_results != "null" and 
                initial_results != None and 
                str(initial_results).strip() != "" and
                len(st.session_state.research_results) == 0):
                
                try:
                    if isinstance(initial_results, str):
                        parsed_results = json.loads(initial_results)
                    else:
                        parsed_results = initial_results
                    
                    if isinstance(parsed_results, list) and len(parsed_results) > 0:
                        st.session_state.research_results = parsed_results
                        # åªåœ¨ç¬¬ä¸€æ¬¡åŠ è½½æ—¶æ˜¾ç¤ºæ¶ˆæ¯ï¼Œé¿å…æ¯æ¬¡åˆ·æ–°éƒ½æ˜¾ç¤º
                        if "first_load_message_shown" not in st.session_state:
                            st.success(f"âœ… å·²åŠ è½½ {len(parsed_results)} æ¡å†å²è®°å½•")
                            st.session_state.first_load_message_shown = True
                except (json.JSONDecodeError, TypeError) as e:
                    st.warning(f"âš ï¸ å†å²è®°å½•æ ¼å¼é”™è¯¯ï¼Œå·²æ¸…ç©º: {e}")
                    localS.removeItem("research_results")
                    # æ¸…é™¤ç¼“å­˜
                    if "ls_research_results" in st.session_state:
                        del st.session_state.ls_research_results
            
            st.session_state.history_loaded = True
        except Exception as e:
            st.warning(f"âš ï¸ åŠ è½½å†å²è®°å½•æ—¶å‡ºé”™: {e}")
            st.session_state.history_loaded = True
    
    # æ˜¾ç¤ºä¾§è¾¹æ 
    sidebar_content()
    
    # æ˜¾ç¤ºä¸»ç•Œé¢
    research_interface()


if __name__ == "__main__":
    main() 