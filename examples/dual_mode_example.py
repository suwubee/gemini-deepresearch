"""
åŒæ¨¡å¼APIä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„åŒæ¨¡å¼æ¶æ„ï¼šGoogle GenAI SDK å’Œ OpenAIå…¼å®¹ HTTP API
"""

import asyncio
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.research_engine import ResearchEngine
from core.api_config import APIConfig, APIMode, ModelConfig
from core.api_factory import APIClientFactory


async def example_basic_usage():
    """åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸ”´ åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    api_key = os.getenv("GEMINI_API_KEY", "your_api_key_here")
    
    # åˆ›å»ºç ”ç©¶å¼•æ“ - é»˜è®¤æ¨¡å¼
    engine = ResearchEngine(
        api_key=api_key,
        model_name="gemini-2.0-flash"
    )
    
    # æŸ¥çœ‹å®¢æˆ·ç«¯ä¿¡æ¯
    print("ğŸ“Š å®¢æˆ·ç«¯ä¿¡æ¯:")
    client_info = engine.get_client_info()
    print(f"  æœç´¢å®¢æˆ·ç«¯: {client_info['search_client']['type']}")
    print(f"  å·¥ä½œæµå®¢æˆ·ç«¯: {client_info['workflow_client']['type']}")
    print(f"  åŒæ¨¡å¼å¯ç”¨: {client_info['dual_mode_enabled']}")
    
    # æ‰§è¡Œç®€å•ç ”ç©¶
    try:
        result = await engine.research(
            user_query="AIå‘å±•è¶‹åŠ¿2024å¹´",
            max_search_rounds=2,
            effort_level="low",
            num_search_queries=2
        )
        
        print(f"âœ… ç ”ç©¶å®Œæˆ: {result['success']}")
        print(f"ğŸ“„ ç­”æ¡ˆé•¿åº¦: {len(result.get('final_answer', ''))}")
        print(f"ğŸ”— å¼•ç”¨æ•°é‡: {len(result.get('citations', []))}")
        
    except Exception as e:
        print(f"âŒ ç ”ç©¶å¤±è´¥: {e}")
    
    # æ¸…ç†
    await engine.close_clients()


async def example_mode_switching():
    """æ¨¡å¼åˆ‡æ¢ç¤ºä¾‹"""
    print("\nğŸŸ¡ æ¨¡å¼åˆ‡æ¢ç¤ºä¾‹")
    print("=" * 50)
    
    api_key = os.getenv("GEMINI_API_KEY", "your_api_key_here")
    
    # æµ‹è¯•ä¸åŒæ¨¡å¼
    modes = [APIMode.GENAI, APIMode.OPENAI]
    
    for mode in modes:
        print(f"\nğŸ”§ æµ‹è¯• {mode.value} æ¨¡å¼:")
        
        try:
            # åˆ›å»ºå¼•æ“å¹¶æŒ‡å®šæ¨¡å¼
            engine = ResearchEngine(
                api_key=api_key,
                model_name="gemini-2.0-flash",
                preferred_mode=mode
            )
            
            # æ˜¾ç¤ºå®¢æˆ·ç«¯ä¿¡æ¯
            client_info = engine.get_client_info()
            print(f"  æœç´¢å®¢æˆ·ç«¯ç±»å‹: {client_info['search_client']['type']}")
            print(f"  æ”¯æŒæœç´¢: {client_info['search_client']['supports_search']}")
            
            # æ‰§è¡Œç®€å•æœç´¢æµ‹è¯•
            result = await engine.search_agent.search_with_grounding(
                "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
                use_search=True
            )
            
            print(f"  æœç´¢æˆåŠŸ: {result.get('success', False)}")
            print(f"  å†…å®¹é•¿åº¦: {len(result.get('content', ''))}")
            print(f"  æœ‰å¼•ç”¨: {result.get('has_grounding', False)}")
            
            await engine.close_clients()
            
        except Exception as e:
            print(f"  âŒ {mode.value} æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")


async def example_configuration():
    """é…ç½®ç®¡ç†ç¤ºä¾‹"""
    print("\nğŸŸ¢ é…ç½®ç®¡ç†ç¤ºä¾‹")
    print("=" * 50)
    
    # æŸ¥çœ‹å¯ç”¨æ¨¡å‹
    print("ğŸ“‹ å¯ç”¨æ¨¡å‹:")
    models_info = APIClientFactory.list_available_models()
    for model_name, info in models_info.items():
        print(f"  {model_name}:")
        print(f"    æ¨¡å¼: {info['mode']}")
        print(f"    æ”¯æŒæœç´¢: {info['supports_search']}")
        print(f"    æ”¯æŒå·¥å…·: {info['supports_tools']}")
    
    # æŸ¥çœ‹å…¨å±€è®¾ç½®
    print(f"\nâš™ï¸ å…¨å±€è®¾ç½®:")
    print(f"  åŒæ¨¡å¼å¯ç”¨: {APIConfig.is_dual_mode_enabled()}")
    print(f"  é»˜è®¤æ¨¡å¼: {APIConfig.DEFAULT_MODE.value}")
    print(f"  Gemini 2.0ä¼˜å…ˆæ¨¡å¼: {APIConfig.get_global_setting('gemini_2_0_preferred_mode').value}")
    
    # åŠ¨æ€æ·»åŠ æ¨¡å‹é…ç½®
    print(f"\nğŸ”§ åŠ¨æ€é…ç½®ç¤ºä¾‹:")
    
    # æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹é…ç½®
    custom_model = ModelConfig(
        name="custom-gpt-4",
        mode=APIMode.OPENAI,
        supports_search=False,
        supports_tools=True,
        base_url="https://api.custom-provider.com/v1",
        default_params={"temperature": 0.2, "max_tokens": 2048}
    )
    
    APIConfig.add_model_config("custom-gpt-4", custom_model)
    print(f"  æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹: custom-gpt-4")
    
    # éªŒè¯é…ç½®
    api_key = os.getenv("GEMINI_API_KEY", "your_api_key_here")
    validation = APIClientFactory.validate_configuration(
        api_key=api_key,
        model_name="gemini-2.0-flash",
        preferred_mode=APIMode.GENAI
    )
    
    print(f"  é…ç½®éªŒè¯: {'âœ… æœ‰æ•ˆ' if validation['valid'] else 'âŒ æ— æ•ˆ'}")
    if validation['errors']:
        print(f"  é”™è¯¯: {validation['errors']}")
    if validation['warnings']:
        print(f"  è­¦å‘Š: {validation['warnings']}")


async def example_advanced_usage():
    """é«˜çº§ä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸ”µ é«˜çº§ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    api_key = os.getenv("GEMINI_API_KEY", "your_api_key_here")
    
    # ä½¿ç”¨é…ç½®åˆ›å»ºå¼•æ“
    engine = ResearchEngine.create_with_config(
        api_key=api_key,
        model_name="gemini-2.5-pro-preview-06-05",
        preferred_mode="genai"  # å­—ç¬¦ä¸²ä¼šè‡ªåŠ¨è½¬æ¢
    )
    
    print("ğŸ¯ ä½¿ç”¨é…ç½®åˆ›å»ºçš„å¼•æ“:")
    client_info = engine.get_client_info()
    print(f"  æœç´¢æ¨¡å‹: {client_info['search_client']['model']}")
    print(f"  å·¥ä½œæµæ¨¡å‹: {client_info['workflow_client']['model']}")
    
    # åˆ‡æ¢æ¨¡å¼
    print(f"\nğŸ”„ åˆ‡æ¢åˆ°OpenAIæ¨¡å¼:")
    try:
        engine.switch_mode(APIMode.OPENAI)
        new_info = engine.get_client_info()
        print(f"  æ–°æœç´¢å®¢æˆ·ç«¯: {new_info['search_client']['type']}")
    except Exception as e:
        print(f"  åˆ‡æ¢å¤±è´¥: {e}")
    
    # è·å–ç¼“å­˜ç»Ÿè®¡
    cache_stats = APIClientFactory.get_cache_stats()
    print(f"\nğŸ“Š å®¢æˆ·ç«¯ç¼“å­˜ç»Ÿè®¡:")
    print(f"  ç¼“å­˜çš„å®¢æˆ·ç«¯æ•°é‡: {cache_stats['cached_clients']}")
    print(f"  ç¼“å­˜é”®: {cache_stats['cache_keys']}")
    
    # æ¸…ç†
    await engine.close_clients()
    APIClientFactory.clear_cache()


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ åŒæ¨¡å¼APIæ¶æ„ç¤ºä¾‹")
    print("=" * 50)
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key or api_key == "your_api_key_here":
        print("âš ï¸ è¯·è®¾ç½®GEMINI_API_KEYç¯å¢ƒå˜é‡")
        print("   export GEMINI_API_KEY='your_actual_api_key'")
        return
    
    try:
        # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
        await example_basic_usage()
        await example_mode_switching()
        await example_configuration()
        await example_advanced_usage()
        
        print("\nâœ… æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main()) 